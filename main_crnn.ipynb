{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "class Dataset_CRNN(data.Dataset):\n",
    "    \"Characterizes a dataset for PyTorch\"\n",
    "    def __init__(self, data_path, folders, labels, frames, transform=None):\n",
    "        \"Initialization\"\n",
    "        self.data_path = data_path\n",
    "        self.labels = labels\n",
    "        self.folders = folders\n",
    "        self.transform = transform\n",
    "        self.frames = frames\n",
    "\n",
    "    def __len__(self):\n",
    "        \"Denotes the total number of samples\"\n",
    "        return len(self.folders)\n",
    "\n",
    "    def read_images(self, path, selected_folder, use_transform):\n",
    "        X = []\n",
    "        for i in self.frames:\n",
    "            image = Image.open(os.path.join(path, selected_folder, 'frame_{:06d}.jpg'.format(i)))\n",
    "\n",
    "            if use_transform is not None:\n",
    "                image = use_transform(image)\n",
    "\n",
    "            X.append(image)\n",
    "        X = torch.stack(X, dim=0)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"Generates one sample of data\"\n",
    "        # Select sample\n",
    "        folder = self.folders[index]\n",
    "\n",
    "        # Load data\n",
    "        X = self.read_images(self.data_path, folder, self.transform)     # (input) spatial images\n",
    "        y = torch.LongTensor([self.labels[index]])                  # (labels) LongTensor are for int64 instead of FloatTensor\n",
    "\n",
    "        # print(X.shape)\n",
    "        return X, y\n",
    "\n",
    "class ResCNNEncoder(nn.Module):\n",
    "    def __init__(self, fc_hidden1=512, fc_hidden2=512, drop_p=0.3, CNN_embed_dim=300):\n",
    "        \"\"\"Load the pretrained ResNet-18 and replace top fc layer.\"\"\"\n",
    "        super(ResCNNEncoder, self).__init__()\n",
    "\n",
    "        self.fc_hidden1, self.fc_hidden2 = fc_hidden1, fc_hidden2\n",
    "        self.drop_p = drop_p\n",
    "\n",
    "        #CNN模型选择\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        modules = list(resnet.children())[:-1]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        \n",
    "        self.fc1 = nn.Linear(resnet.fc.in_features, fc_hidden1)\n",
    "        self.bn1 = nn.BatchNorm1d(fc_hidden1, momentum=0.01)\n",
    "        self.fc2 = nn.Linear(fc_hidden1, fc_hidden2)\n",
    "        self.bn2 = nn.BatchNorm1d(fc_hidden2, momentum=0.01)\n",
    "        self.fc3 = nn.Linear(fc_hidden2, CNN_embed_dim)\n",
    "\n",
    "    def forward(self, x_3d):\n",
    "        cnn_embed_seq = []\n",
    "        for t in range(x_3d.size(1)):\n",
    "            with torch.no_grad():\n",
    "                x = self.resnet(x_3d[:, t, :, :, :])\n",
    "                x = x.view(x.size(0), -1)\n",
    "\n",
    "            x = self.bn1(self.fc1(x))\n",
    "            x = F.relu(x)\n",
    "            x = self.bn2(self.fc2(x))\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.drop_p, training=self.training)\n",
    "            x = self.fc3(x)\n",
    "            cnn_embed_seq.append(x)\n",
    "\n",
    "        cnn_embed_seq = torch.stack(cnn_embed_seq, dim=0).transpose_(0, 1)\n",
    "        return cnn_embed_seq\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, CNN_embed_dim=300, h_RNN_layers=3, h_RNN=256, h_FC_dim=128, drop_p=0.3, num_classes=50):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        self.RNN_input_size = CNN_embed_dim\n",
    "        self.h_RNN_layers = h_RNN_layers   # RNN hidden layers\n",
    "        self.h_RNN = h_RNN                 # RNN hidden nodes\n",
    "        self.h_FC_dim = h_FC_dim\n",
    "        self.drop_p = drop_p\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.LSTM = nn.LSTM(\n",
    "            input_size=self.RNN_input_size,\n",
    "            hidden_size=self.h_RNN,        \n",
    "            num_layers=h_RNN_layers,       \n",
    "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(self.h_RNN, self.h_FC_dim)\n",
    "        self.fc2 = nn.Linear(self.h_FC_dim, self.num_classes)\n",
    "\n",
    "    def forward(self, x_RNN):\n",
    "        \n",
    "        self.LSTM.flatten_parameters()\n",
    "        RNN_out, (h_n, h_c) = self.LSTM(x_RNN, None)  \n",
    "        \"\"\" h_n shape (n_layers, batch, hidden_size), h_c shape (n_layers, batch, hidden_size) \"\"\" \n",
    "        \"\"\" None represents zero initial hidden state. RNN_out has shape=(batch, time_step, output_size) \"\"\"\n",
    "\n",
    "        # FC layers\n",
    "        x = self.fc1(RNN_out[:, -1, :])   # choose RNN_out at the last time step\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.drop_p, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def labels2cat(label_encoder, actions):\n",
    "    return label_encoder.transform(actions)\n",
    "\n",
    "def CRNN_final_prediction(model, device, loader):\n",
    "    cnn_encoder, rnn_decoder = model\n",
    "    cnn_encoder.eval()\n",
    "    rnn_decoder.eval()\n",
    "\n",
    "    all_y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (X, y) in enumerate(tqdm(loader)):\n",
    "            # distribute data to device\n",
    "            X = X.to(device)\n",
    "            output = rnn_decoder(cnn_encoder(X))\n",
    "            y_pred = output.max(1, keepdim=True)[1]  # location of max log-probability as prediction\n",
    "            all_y_pred.extend(y_pred.cpu().data.squeeze().numpy().tolist())\n",
    "\n",
    "    return all_y_pred\n",
    "\n",
    "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
    "    \"\"\"Training function for one epoch\"\"\"\n",
    "    cnn_encoder, rnn_decoder = model\n",
    "    cnn_encoder.train()\n",
    "    rnn_decoder.train()\n",
    "\n",
    "    losses = []\n",
    "    scores = []\n",
    "    N_count = 0  # Count of processed samples\n",
    "    \n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.to(device), y.to(device).view(-1, )\n",
    "        N_count += X.size(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = rnn_decoder(cnn_encoder(X))\n",
    "        loss = F.cross_entropy(output, y)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Calculate accuracy\n",
    "        y_pred = torch.max(output, 1)[1]\n",
    "        step_score = accuracy_score(y.cpu().data.squeeze().numpy(), y_pred.cpu().data.squeeze().numpy())\n",
    "        scores.append(step_score)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Log training progress\n",
    "        if (batch_idx + 1) % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accu: {:.2f}%'.format(\n",
    "                epoch + 1, N_count, len(train_loader.dataset),\n",
    "                100. * (batch_idx + 1) / len(train_loader), loss.item(), 100 * step_score))\n",
    "    \n",
    "    return losses, scores\n",
    "\n",
    "def validation(model, device, optimizer, test_loader):\n",
    "    \"\"\"Validation function\"\"\"\n",
    "    cnn_encoder, rnn_decoder = model\n",
    "    cnn_encoder.eval()\n",
    "    rnn_decoder.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    all_y = []\n",
    "    all_y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            X, y = X.to(device), y.to(device).view(-1, )\n",
    "            output = rnn_decoder(cnn_encoder(X))\n",
    "            loss = F.cross_entropy(output, y, reduction='sum')\n",
    "            test_loss += loss.item()\n",
    "            y_pred = output.max(1, keepdim=True)[1]\n",
    "            all_y.extend(y)\n",
    "            all_y_pred.extend(y_pred)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    all_y = torch.stack(all_y, dim=0)\n",
    "    all_y_pred = torch.stack(all_y_pred, dim=0)\n",
    "    test_score = accuracy_score(all_y.cpu().data.squeeze().numpy(), all_y_pred.cpu().data.squeeze().numpy())\n",
    "\n",
    "    print('\\nValid set ({:d} samples): Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(\n",
    "        len(all_y), test_loss, 100* test_score))\n",
    "    \n",
    "    return test_loss, test_score\n",
    "\n",
    "## ---------------------- end of CRNN module ---------------------- ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data path configuration\n",
    "data_path = \"./WB_Set B_jpg\"\n",
    "\n",
    "# Define result saving paths\n",
    "save_path = \"./output__crnn\"\n",
    "save_model_path = os.path.join(save_path, \"models\")\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "os.makedirs(save_model_path, exist_ok=True)\n",
    "\n",
    "# Model parameters\n",
    "CNN_fc_hidden1, CNN_fc_hidden2 = 1024, 768\n",
    "CNN_embed_dim = 512\n",
    "res_size = 224\n",
    "dropout_p = 0.3\n",
    "RNN_hidden_layers = 3\n",
    "RNN_hidden_nodes = 512\n",
    "RNN_FC_dim = 256\n",
    "k = 3  # Number of classes\n",
    "epochs = 50\n",
    "batch_size = 50\n",
    "learning_rate = 1e-3\n",
    "log_interval = 10  # Log training info every N batches\n",
    "patience = 5  # Early stopping patience\n",
    "no_improve_count = 0  # Counter for early stopping\n",
    "begin_frame, end_frame, skip_frame = 1, 60, 1  # Frame selection parameters\n",
    "\n",
    "# CUDA settings\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 4, 'pin_memory': True} if use_cuda else {'batch_size': batch_size, 'shuffle': True}\n",
    "\n",
    "# Action class names and label encoding\n",
    "action_names = ['Plunging', 'Spilling', 'Surging']\n",
    "le = LabelEncoder()\n",
    "le.fit(action_names)\n",
    "action_category = le.transform(action_names).reshape(-1, 1)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(action_category)\n",
    "\n",
    "# Load all filenames and extract actions\n",
    "fnames = os.listdir(data_path)\n",
    "actions = []\n",
    "all_names = []\n",
    "for f in fnames:\n",
    "    loc = f.find('_')\n",
    "    if loc == -1:\n",
    "        print(f\"Unexpected file format: {f}\")\n",
    "        continue\n",
    "    action = f[:loc]\n",
    "    actions.append(action)\n",
    "    all_names.append(f)\n",
    "\n",
    "# Prepare data lists\n",
    "all_X_list = all_names\n",
    "all_y_list = labels2cat(le, actions)\n",
    "\n",
    "# Setup stratified k-fold cross validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize([res_size, res_size]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Frame selection\n",
    "selected_frames = np.arange(begin_frame, end_frame, skip_frame).tolist()\n",
    "\n",
    "# Initialize best validation score\n",
    "best_valid_score = -float('inf')\n",
    "fold = 1  # Current fold counter\n",
    "\n",
    "# File suffixes to check for completed folds\n",
    "file_suffixes = [\n",
    "    'epoch_training_losses.npy',\n",
    "    'epoch_training_scores.npy',\n",
    "    'epoch_validation_loss.npy',\n",
    "    'epoch_validation_score.npy',\n",
    "]\n",
    "\n",
    "# Main training loop with k-fold cross validation\n",
    "for train_index, valid_index in skf.split(all_X_list, all_y_list):\n",
    "    # Check if current fold is already completed\n",
    "    fold_completed = all(os.path.exists(os.path.join(save_path, f'CRNN_fold_{fold}_{suffix}')) for suffix in file_suffixes)\n",
    "    \n",
    "    if fold_completed:\n",
    "        print(f\"\\nFold {fold} already completed. Skipping to next fold...\\n\")\n",
    "        fold += 1\n",
    "        continue\n",
    "    \n",
    "    print(f\"Fold {fold}:\")\n",
    "    # Split data into training and validation sets\n",
    "    train_list = [all_X_list[i] for i in train_index]\n",
    "    valid_list = [all_X_list[i] for i in valid_index]\n",
    "    train_label = [all_y_list[i] for i in train_index]\n",
    "    valid_label = [all_y_list[i] for i in valid_index]\n",
    "\n",
    "    # Create datasets and data loaders\n",
    "    train_set = Dataset_CRNN(data_path, train_list, train_label, selected_frames, transform=transform)\n",
    "    valid_set = Dataset_CRNN(data_path, valid_list, valid_label, selected_frames, transform=transform)\n",
    "    train_loader = DataLoader(train_set, **params)\n",
    "    valid_loader = DataLoader(valid_set, **params)\n",
    "\n",
    "    # Initialize models\n",
    "    cnn_encoder = ResCNNEncoder(fc_hidden1=CNN_fc_hidden1, fc_hidden2=CNN_fc_hidden2, \n",
    "                               drop_p=dropout_p, CNN_embed_dim=CNN_embed_dim).to(device)\n",
    "    rnn_decoder = DecoderRNN(CNN_embed_dim=CNN_embed_dim, h_RNN_layers=RNN_hidden_layers, \n",
    "                            h_RNN=RNN_hidden_nodes, h_FC_dim=RNN_FC_dim, \n",
    "                            drop_p=dropout_p, num_classes=k).to(device)\n",
    "\n",
    "    # Multi-GPU support if available\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        cnn_encoder = nn.DataParallel(cnn_encoder)\n",
    "        rnn_decoder = nn.DataParallel(rnn_decoder)\n",
    "        crnn_params = (list(cnn_encoder.module.fc1.parameters()) + list(cnn_encoder.module.bn1.parameters()) +\n",
    "                       list(cnn_encoder.module.fc2.parameters()) + list(cnn_encoder.module.bn2.parameters()) +\n",
    "                       list(cnn_encoder.module.fc3.parameters()) + list(rnn_decoder.parameters()))\n",
    "    else:\n",
    "        print(\"Using\", torch.cuda.device_count(), \"GPU!\")\n",
    "        crnn_params = (list(cnn_encoder.fc1.parameters()) + list(cnn_encoder.bn1.parameters()) +\n",
    "                       list(cnn_encoder.fc2.parameters()) + list(cnn_encoder.bn2.parameters()) +\n",
    "                       list(cnn_encoder.fc3.parameters()) + list(rnn_decoder.parameters()))\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.Adam(crnn_params, lr=learning_rate)\n",
    "\n",
    "    # Initialize lists to track metrics\n",
    "    epoch_train_losses = []\n",
    "    epoch_train_scores = []\n",
    "    epoch_valid_losses = []\n",
    "    epoch_valid_scores = []\n",
    "\n",
    "    # Early stopping counters\n",
    "    no_improve_count = 0\n",
    "    current_best_valid_score = -float('inf')\n",
    "\n",
    "    # Training loop for current fold\n",
    "    for epoch in range(epochs):\n",
    "        train_losses, train_scores = train(log_interval, [cnn_encoder, rnn_decoder], device, train_loader, optimizer, epoch)\n",
    "        epoch_valid_loss, epoch_valid_score = validation([cnn_encoder, rnn_decoder], device, optimizer, valid_loader)\n",
    "\n",
    "        # Store metrics\n",
    "        epoch_train_losses.append(train_losses)\n",
    "        epoch_train_scores.append(train_scores)\n",
    "        epoch_valid_losses.append(epoch_valid_loss)\n",
    "        epoch_valid_scores.append(epoch_valid_score)\n",
    "\n",
    "        # Check for improvement and save best model\n",
    "        if epoch_valid_score > current_best_valid_score:\n",
    "            current_best_valid_score = epoch_valid_score\n",
    "            no_improve_count = 0\n",
    "            # Save model state dicts\n",
    "            torch.save(cnn_encoder.state_dict(), os.path.join(save_model_path, f'best_cnn_encoder_fold_{fold}.pth'))\n",
    "            torch.save(rnn_decoder.state_dict(), os.path.join(save_model_path, f'best_rnn_decoder_fold_{fold}.pth'))\n",
    "            torch.save(optimizer.state_dict(), os.path.join(save_model_path, f'best_optimizer_fold_{fold}.pth'))\n",
    "            # Save full models\n",
    "            torch.save(cnn_encoder, os.path.join(save_model_path, f'best_cnn_encoder_full_fold_{fold}.pth'))\n",
    "            torch.save(rnn_decoder, os.path.join(save_model_path, f'best_rnn_decoder_full_fold_{fold}.pth'))\n",
    "            print(f\"Epoch {epoch + 1} in Fold {fold}: Best model saved with validation score {epoch_valid_score:.2f}\")\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "            print(f\"Epoch {epoch + 1} in Fold {fold}: No improvement in validation score. Count={no_improve_count}\")\n",
    "            if no_improve_count > patience:\n",
    "                print(\"Early stopping triggered for current fold.\")\n",
    "                break\n",
    "\n",
    "        # Update global best validation score\n",
    "        if current_best_valid_score > best_valid_score:\n",
    "            best_valid_score = current_best_valid_score\n",
    "\n",
    "    # Save training metrics for current fold\n",
    "    A = np.array(epoch_train_losses)\n",
    "    B = np.array(epoch_train_scores)\n",
    "    C = np.array(epoch_valid_losses)\n",
    "    D = np.array(epoch_valid_scores)\n",
    "\n",
    "    np.save(os.path.join(save_path, f'CRNN_fold_{fold}_epoch_training_losses.npy'), A)\n",
    "    np.save(os.path.join(save_path, f'CRNN_fold_{fold}_epoch_training_scores.npy'), B)\n",
    "    np.save(os.path.join(save_path, f'CRNN_fold_{fold}_epoch_validation_loss.npy'), C)\n",
    "    np.save(os.path.join(save_path, f'CRNN_fold_{fold}_epoch_validation_score.npy'), D)\n",
    "\n",
    "    print(f\"Fold {fold} training complete.\")\n",
    "\n",
    "    # Clean up memory\n",
    "    del cnn_encoder\n",
    "    del rnn_decoder\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    fold += 1  # Move to next fold\n",
    "\n",
    "print(f\"Cross-validation complete. Best validation score: {best_valid_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
